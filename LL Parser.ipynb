{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LL Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following small LL(1) grammar:\n",
    "\n",
    "```\n",
    "1. S → F\n",
    "2. S → ( S + F )\n",
    "3. F → a\n",
    "```\n",
    "\n",
    "and parse the following input: **( a + a )**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we impement lexical analyser\n",
    "- Define `TOKEN` type that lists of token in our language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\r\n",
       "<div>\r\n",
       "    <div id='dotnet-interactive-this-cell-66944.14515b466cb643cb903ce9efa2a6e933' style='display: none'>\r\n",
       "        The below script needs to be able to find the current output cell; this is an easy method to get it.\r\n",
       "    </div>\r\n",
       "    <script type='text/javascript'>\r\n",
       "// ensure `require` is available globally\r\n",
       "if (typeof require !== typeof Function || typeof require.config !== typeof Function) {\r\n",
       "    let require_script = document.createElement('script');\r\n",
       "    require_script.setAttribute('src', 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js');\r\n",
       "    require_script.setAttribute('type', 'text/javascript');\r\n",
       "    require_script.onload = function () {\r\n",
       "        loadDotnetInteractiveApi();\r\n",
       "    };\r\n",
       "\r\n",
       "    document.getElementsByTagName('head')[0].appendChild(require_script);\r\n",
       "}\r\n",
       "else {\r\n",
       "    loadDotnetInteractiveApi();\r\n",
       "}\r\n",
       "\r\n",
       "async function probeAddresses(probingAddresses) {\r\n",
       "    function timeout(ms, promise) {\r\n",
       "        return new Promise(function (resolve, reject) {\r\n",
       "            setTimeout(function () {\r\n",
       "                reject(new Error('timeout'))\r\n",
       "            }, ms)\r\n",
       "            promise.then(resolve, reject)\r\n",
       "        })\r\n",
       "    }\r\n",
       "\r\n",
       "    if (Array.isArray(probingAddresses)) {\r\n",
       "        for (let i = 0; i < probingAddresses.length; i++) {\r\n",
       "\r\n",
       "            let rootUrl = probingAddresses[i];\r\n",
       "\r\n",
       "            if (!rootUrl.endsWith('/')) {\r\n",
       "                rootUrl = `${rootUrl}/`;\r\n",
       "            }\r\n",
       "\r\n",
       "            try {\r\n",
       "                let response = await timeout(1000, fetch(`${rootUrl}discovery`, {\r\n",
       "                    method: 'POST',\r\n",
       "                    cache: 'no-cache',\r\n",
       "                    mode: 'cors',\r\n",
       "                    timeout: 1000,\r\n",
       "                    headers: {\r\n",
       "                        'Content-Type': 'text/plain'\r\n",
       "                    },\r\n",
       "                    body: probingAddresses[i]\r\n",
       "                }));\r\n",
       "\r\n",
       "                if (response.status == 200) {\r\n",
       "                    return rootUrl;\r\n",
       "                }\r\n",
       "            }\r\n",
       "            catch (e) { }\r\n",
       "        }\r\n",
       "    }\r\n",
       "}\r\n",
       "\r\n",
       "function loadDotnetInteractiveApi() {\r\n",
       "    probeAddresses([\"http://192.168.0.201:1026/\", \"http://127.0.0.1:1026/\"])\r\n",
       "        .then((root) => {\r\n",
       "            // use probing to find host url and api resources\r\n",
       "            // load interactive helpers and language services\r\n",
       "            let dotnetInteractiveRequire = require.config({\r\n",
       "                context: '66944.14515b466cb643cb903ce9efa2a6e933',\r\n",
       "                paths: {\r\n",
       "                    'dotnet-interactive': `${root}resources`\r\n",
       "                }\r\n",
       "            }) || require;\r\n",
       "\r\n",
       "            let dotnetInteractiveExtensionsRequire = require.config({\r\n",
       "                context: '66944.14515b466cb643cb903ce9efa2a6e933',\r\n",
       "                paths: {\r\n",
       "                    'dotnet-interactive-extensions': `${root}extensions`\r\n",
       "                }\r\n",
       "            }) || require;\r\n",
       "\r\n",
       "            window.dotnetInteractiveRequire = dotnetInteractiveRequire;\r\n",
       "            window.dotnetInteractiveExtensionsRequire = dotnetInteractiveExtensionsRequire;\r\n",
       "            window.getExtensionRequire = function(extensionName, extensionCacheBuster) {\r\n",
       "                let paths = {};\r\n",
       "                paths[extensionName] = `${root}extensions/${extensionName}/resources/`;\r\n",
       "                \r\n",
       "                let internalRequire = require.config({\r\n",
       "                    context: extensionCacheBuster,\r\n",
       "                    paths: paths,\r\n",
       "                    urlArgs: `cacheBuster=${extensionCacheBuster}`\r\n",
       "                    }) || require;\r\n",
       "\r\n",
       "                return internalRequire\r\n",
       "            };\r\n",
       "        \r\n",
       "            dotnetInteractiveRequire([\r\n",
       "                    'dotnet-interactive/dotnet-interactive'\r\n",
       "                ],\r\n",
       "                function (dotnet) {\r\n",
       "                    dotnet.init(window);\r\n",
       "                },\r\n",
       "                function (error) {\r\n",
       "                    console.log(error);\r\n",
       "                }\r\n",
       "            );\r\n",
       "        })\r\n",
       "        .catch(error => {console.log(error);});\r\n",
       "    }\r\n",
       "    </script>\r\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type TOKEN = LPAR | RPAR | PLUS | MINUS | A | B | C | INVALID | END\n",
    "\n",
    "// lexical analyser\n",
    "let tokenize input =\n",
    "    if Seq.isEmpty input then\n",
    "        TOKEN.END, Seq.empty<char>\n",
    "    else\n",
    "        let C = Seq.head input\n",
    "        let S = Seq.tail input\n",
    "        let T = match C with\n",
    "                | '(' -> TOKEN.LPAR\n",
    "                | ')' -> TOKEN.RPAR\n",
    "                | '+' -> TOKEN.PLUS\n",
    "                | '-' -> TOKEN.MINUS\n",
    "                | 'a' -> TOKEN.A\n",
    "                | 'b' -> TOKEN.B\n",
    "                | 'c' -> TOKEN.C\n",
    "                | _   -> TOKEN.INVALID\n",
    "        T, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th>Item1</th><th>Item2</th></tr></thead><tbody><tr><td><div class=\"dni-plaintext\">A</div></td><td><div class=\"dni-plaintext\">[ +, a ]</div></td></tr></tbody></table>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize \"a+a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Function generates a sequance of tokens from the input string\n",
    "let tokens input =\n",
    "    let tokenizeNext state =\n",
    "        match state with\n",
    "        | TOKEN.END, _ -> None\n",
    "        | _ -> let S = state |> snd |> tokenize\n",
    "               Some(S, S)\n",
    "    Seq.unfold (tokenizeNext) (TOKEN.INVALID, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>Item1</th><th>Item2</th></tr></thead><tbody><tr><td>0</td><td><div class=\"dni-plaintext\">LPAR</div></td><td><div class=\"dni-plaintext\">[ a, +, a, ) ]</div></td></tr><tr><td>1</td><td><div class=\"dni-plaintext\">A</div></td><td><div class=\"dni-plaintext\">[ +, a, ) ]</div></td></tr><tr><td>2</td><td><div class=\"dni-plaintext\">PLUS</div></td><td><div class=\"dni-plaintext\">[ a, ) ]</div></td></tr><tr><td>3</td><td><div class=\"dni-plaintext\">A</div></td><td><div class=\"dni-plaintext\">[ ) ]</div></td></tr><tr><td>4</td><td><div class=\"dni-plaintext\">RPAR</div></td><td><div class=\"dni-plaintext\">[  ]</div></td></tr><tr><td>5</td><td><div class=\"dni-plaintext\">END</div></td><td><div class=\"dni-plaintext\">[  ]</div></td></tr></tbody></table>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens \"(a+a)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPAR A PLUS A RPAR END "
     ]
    }
   ],
   "source": [
    "for (t,s) in tokens \"(a+a)\" do\n",
    "    printf \"%A \" t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we construct a parsing table for this grammar by expanding all the terminals by column and all nonterminals by row: \n",
    "\n",
    "N\\T|(|)|a|+|$\n",
    "---|-|-|-|-|\n",
    "S  |2| |1| |\n",
    "F  | | |3| |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define types requred to construct grammar rules, and define grammar and above table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "type RULE = S | F\n",
    "\n",
    "type SYMBOL =\n",
    "    | Terminal of TOKEN\n",
    "    | NonTerminal of RULE\n",
    "    | Error\n",
    "\n",
    "let grammar = [|\n",
    "    (SYMBOL.NonTerminal RULE.S, [SYMBOL.NonTerminal RULE.F]);  // S → F\n",
    "    (SYMBOL.NonTerminal RULE.S, [SYMBOL.Terminal TOKEN.LPAR;   // S → ( S + F )\n",
    "                                 SYMBOL.NonTerminal RULE.S;\n",
    "                                 SYMBOL.Terminal TOKEN.PLUS;\n",
    "                                 SYMBOL.NonTerminal RULE.F;\n",
    "                                 SYMBOL.Terminal TOKEN.RPAR]); // F → a\n",
    "    (SYMBOL.NonTerminal RULE.F, [SYMBOL.Terminal TOKEN.A])\n",
    "|]\n",
    "\n",
    "let table = [\n",
    "     (RULE.S, TOKEN.A);    // Rule 1: parse table location [S, a]\n",
    "     (RULE.S, TOKEN.LPAR); // Rule 2: parse table location [S, )]\n",
    "     (RULE.F, TOKEN.A);    // Rule 3: parse table location [F, a]\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Stack helper functions\n",
    "let push sym stk = sym::stk\n",
    "\n",
    "let top stk = List.head stk\n",
    "\n",
    "let pop stk =\n",
    "    match stk with\n",
    "    | top::tl -> top, tl\n",
    "    | _ -> SYMBOL.Error, List.empty<SYMBOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a syntactic analyser function `parser` that accepts:\n",
    "- grammar description\n",
    "- parse table\n",
    "- string input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "// syntactic analyser\n",
    "let parser (grammar: (SYMBOL * SYMBOL list)[]) table input =\n",
    "    // Push a $ on the stack\n",
    "    // Initialize the stack to the start symbol.\n",
    "    let stack = List.empty<SYMBOL> |>\n",
    "                push (Terminal TOKEN.END) |>\n",
    "                push (NonTerminal RULE.S)\n",
    "\n",
    "    let rec analyse stack (token, input) =\n",
    "        printfn \"Token: %A, Stack: %A\" token stack\n",
    "        if List.length stack > 0 then\n",
    "            // take element from top of the stack\n",
    "            let sym = top stack\n",
    "            // get next token\n",
    "            match sym with\n",
    "            | Terminal term ->\n",
    "                if term = token then // input symbol matches terminal\n",
    "                    // pop stack\n",
    "                    let t, new_stack = pop stack\n",
    "                    printfn \"pop %A\" t\n",
    "                    analyse new_stack (tokenize input) // advance input\n",
    "                else\n",
    "                    failwith (sprintf \"bad term on input: %A\" token)\n",
    "            | NonTerminal nterm ->\n",
    "                begin\n",
    "                    // Use nonterminal and current input symbol to find correct production in table.\n",
    "                    printfn \"svalue: %A, token: %A\" nterm token\n",
    "                    let rule_idx = \n",
    "                        try \n",
    "                            List.findIndex (fun (r,t) -> r = nterm && t = token) table\n",
    "                        with\n",
    "                            | :? System.Collections.Generic.KeyNotFoundException -> failwith (sprintf \"No rule found for %A → %A\" nterm token)                    \n",
    "                    let rule = grammar.[rule_idx]\n",
    "                    printfn \"%d: %A → %A\" (rule_idx + 1) (fst rule) (snd rule)\n",
    "\n",
    "                    // Pop stack\n",
    "                    // Push right-hand side of production from table onto stack, last symbol first.\n",
    "                    let new_stack = List.append (snd rule) (stack |> pop |> snd)\n",
    "                    analyse new_stack (token, input)\n",
    "                end\n",
    "            | _ -> failwith \"error\"\n",
    "        else ()\n",
    "\n",
    "    analyse stack (tokenize input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our parser with different inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: LPAR, Stack: [NonTerminal S; Terminal END]\n",
      "svalue: S, token: LPAR\n",
      "2: NonTerminal S → [Terminal LPAR; NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR]\n",
      "Token: LPAR, Stack: [Terminal LPAR; NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR;\n",
      " Terminal END]\n",
      "pop Terminal LPAR\n",
      "Token: A, Stack: [NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "svalue: S, token: A\n",
      "1: NonTerminal S → [NonTerminal F]\n",
      "Token: A, Stack: [NonTerminal F; Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "svalue: F, token: A\n",
      "3: NonTerminal F → [Terminal A]\n",
      "Token: A, Stack: [Terminal A; Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "pop Terminal A\n",
      "Token: PLUS, Stack: [Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "pop Terminal PLUS\n",
      "Token: A, Stack: [NonTerminal F; Terminal RPAR; Terminal END]\n",
      "svalue: F, token: A\n",
      "3: NonTerminal F → [Terminal A]\n",
      "Token: A, Stack: [Terminal A; Terminal RPAR; Terminal END]\n",
      "pop Terminal A\n",
      "Token: RPAR, Stack: [Terminal RPAR; Terminal END]\n",
      "pop Terminal RPAR\n",
      "Token: END, Stack: [Terminal END]\n",
      "pop Terminal END\n",
      "Token: END, Stack: []\n"
     ]
    }
   ],
   "source": [
    "parser grammar table \"(a+a)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: LPAR, Stack: [NonTerminal S; Terminal END]\n",
      "svalue: S, token: LPAR\n",
      "2: NonTerminal S → [Terminal LPAR; NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR]\n",
      "Token: LPAR, Stack: [Terminal LPAR; NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR;\n",
      " Terminal END]\n",
      "pop Terminal LPAR\n",
      "Token: LPAR, Stack: [NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "svalue: S, token: LPAR\n",
      "2: NonTerminal S → [Terminal LPAR; NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR]\n",
      "Token: LPAR, Stack: [Terminal LPAR; NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR;\n",
      " Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "pop Terminal LPAR\n",
      "Token: A, Stack: [NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal PLUS;\n",
      " NonTerminal F; Terminal RPAR; Terminal END]\n",
      "svalue: S, token: A\n",
      "1: NonTerminal S → [NonTerminal F]\n",
      "Token: A, Stack: [NonTerminal F; Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal PLUS;\n",
      " NonTerminal F; Terminal RPAR; Terminal END]\n",
      "svalue: F, token: A\n",
      "3: NonTerminal F → [Terminal A]\n",
      "Token: A, Stack: [Terminal A; Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal PLUS;\n",
      " NonTerminal F; Terminal RPAR; Terminal END]\n",
      "pop Terminal A\n",
      "Token: PLUS, Stack: [Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal PLUS; NonTerminal F;\n",
      " Terminal RPAR; Terminal END]\n",
      "pop Terminal PLUS\n",
      "Token: A, Stack: [NonTerminal F; Terminal RPAR; Terminal PLUS; NonTerminal F; Terminal RPAR;\n",
      " Terminal END]\n",
      "svalue: F, token: A\n",
      "3: NonTerminal F → [Terminal A]\n",
      "Token: A, Stack: [Terminal A; Terminal RPAR; Terminal PLUS; NonTerminal F; Terminal RPAR;\n",
      " Terminal END]\n",
      "pop Terminal A\n",
      "Token: RPAR, Stack: [Terminal RPAR; Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "pop Terminal RPAR\n",
      "Token: PLUS, Stack: [Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "pop Terminal PLUS\n",
      "Token: A, Stack: [NonTerminal F; Terminal RPAR; Terminal END]\n",
      "svalue: F, token: A\n",
      "3: NonTerminal F → [Terminal A]\n",
      "Token: A, Stack: [Terminal A; Terminal RPAR; Terminal END]\n",
      "pop Terminal A\n",
      "Token: RPAR, Stack: [Terminal RPAR; Terminal END]\n",
      "pop Terminal RPAR\n",
      "Token: END, Stack: [Terminal END]\n",
      "pop Terminal END\n",
      "Token: END, Stack: []\n"
     ]
    }
   ],
   "source": [
    "parser grammar table \"((a+a)+a)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: LPAR, Stack: [NonTerminal S; Terminal END]\n",
      "svalue: S, token: LPAR\n",
      "2: NonTerminal S → [Terminal LPAR; NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR]\n",
      "Token: LPAR, Stack: [Terminal LPAR; NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR;\n",
      " Terminal END]\n",
      "pop Terminal LPAR\n",
      "Token: A, Stack: [NonTerminal S; Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "svalue: S, token: A\n",
      "1: NonTerminal S → [NonTerminal F]\n",
      "Token: A, Stack: [NonTerminal F; Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "svalue: F, token: A\n",
      "3: NonTerminal F → [Terminal A]\n",
      "Token: A, Stack: [Terminal A; Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "pop Terminal A\n",
      "Token: PLUS, Stack: [Terminal PLUS; NonTerminal F; Terminal RPAR; Terminal END]\n",
      "pop Terminal PLUS\n",
      "Token: RPAR, Stack: [NonTerminal F; Terminal RPAR; Terminal END]\n",
      "svalue: F, token: RPAR\n"
     ]
    },
    {
     "ename": "Unhandled exception",
     "evalue": "System.Exception: No rule found for F → RPAR\n   at FSI_0011.analyse@9(Tuple`2[] grammar, FSharpList`1 table, FSharpList`1 stack, TOKEN tupledArg0, IEnumerable`1 tupledArg1)\n   at FSI_0011.parser(Tuple`2[] grammar, FSharpList`1 table, IEnumerable`1 input)\n   at <StartupCode$FSI_0014>.$FSI_0014.main@()",
     "output_type": "error",
     "traceback": [
      "System.Exception: No rule found for F → RPAR\n   at FSI_0011.analyse@9(Tuple`2[] grammar, FSharpList`1 table, FSharpList`1 stack, TOKEN tupledArg0, IEnumerable`1 tupledArg1)\n   at FSI_0011.parser(Tuple`2[] grammar, FSharpList`1 table, IEnumerable`1 input)\n   at <StartupCode$FSI_0014>.$FSI_0014.main@()",
      "   at FSI_0011.analyse@9(Tuple`2[] grammar, FSharpList`1 table, FSharpList`1 stack, TOKEN tupledArg0, IEnumerable`1 tupledArg1)",
      "   at FSI_0011.parser(Tuple`2[] grammar, FSharpList`1 table, IEnumerable`1 input)",
      "   at <StartupCode$FSI_0014>.$FSI_0014.main@()"
     ]
    }
   ],
   "source": [
    "parser grammar table \"(a+)\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (F#)",
   "language": "F#",
   "name": ".net-fsharp"
  },
  "language": "fsharp",
  "language_info": {
   "file_extension": ".fs",
   "mimetype": "text/x-fsharp",
   "name": "C#",
   "pygments_lexer": "fsharp",
   "version": "4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
